{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent network for fake news classification using tokens/embedding for single words instead of embedding for whole document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision --quiet\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# nlp stuff\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "import nlp_nets as nlp\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from os.path import join as opj\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'/Users/AdamHarris/Documents/neuromatch_nlp/Neuromatch_NLP/dataset'\n",
    "\n",
    "test_df = pd.read_csv(f'{data_folder}/test_df.csv')\n",
    "val_df = pd.read_csv(f'{data_folder}/validation_df_embeddings.csv')\n",
    "train_df = pd.read_csv(f'{data_folder}/train_df_embeddings.csv')\n",
    "\n",
    "test_txt = test_df['text']\n",
    "test_label = test_df['label']\n",
    "\n",
    "\n",
    "train_txt = train_df['text']\n",
    "train_label = train_df['label']\n",
    "\n",
    "\n",
    "val_txt = val_df['text']\n",
    "val_label = val_df['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation and word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [tokenize(text) for text in train_txt]\n",
    "tokenized_val = [tokenize(text) for text in val_txt]\n",
    "tokenized_test = [tokenize(text) for text in test_txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video',\n",
       " 'hillary',\n",
       " 'left',\n",
       " 'want',\n",
       " 'america',\n",
       " 'see',\n",
       " 'today',\n",
       " 'compelled',\n",
       " 'sit',\n",
       " 'write',\n",
       " 'letter',\n",
       " 'anyone',\n",
       " 'particular',\n",
       " 'maybe',\n",
       " 'even',\n",
       " 'black',\n",
       " 'female',\n",
       " 'executive',\n",
       " 'trump',\n",
       " 'organization',\n",
       " 'longer',\n",
       " 'remain',\n",
       " 'silent',\n",
       " 'repeated',\n",
       " 'reprehensible',\n",
       " 'attempts',\n",
       " 'align',\n",
       " 'boss',\n",
       " 'family',\n",
       " 'racist',\n",
       " 'hate',\n",
       " 'mongering',\n",
       " 'groups',\n",
       " 'campaigns',\n",
       " 'messaging',\n",
       " 'daughter',\n",
       " 'man',\n",
       " 'born',\n",
       " 'birmingham',\n",
       " 'alabama',\n",
       " 'rose',\n",
       " 'odds',\n",
       " 'become',\n",
       " 'one',\n",
       " 'established',\n",
       " 'respected',\n",
       " 'doctor',\n",
       " 'yale',\n",
       " 'university',\n",
       " 'amount',\n",
       " 'money',\n",
       " 'world',\n",
       " 'could',\n",
       " 'buy',\n",
       " 'loyalty',\n",
       " 'family',\n",
       " 'subscribed',\n",
       " 'intolerant',\n",
       " 'bigoted',\n",
       " 'ideologies',\n",
       " 'lynne',\n",
       " 'patton',\n",
       " 'reading',\n",
       " 'powerful',\n",
       " 'letter',\n",
       " 'penned',\n",
       " 'dispel',\n",
       " 'lies',\n",
       " 'donald',\n",
       " 'j',\n",
       " 'trump',\n",
       " 'well',\n",
       " 'family',\n",
       " 'linkedin',\n",
       " 'lynn',\n",
       " 'patton',\n",
       " 'chief',\n",
       " 'staff',\n",
       " 'eric',\n",
       " 'trump',\n",
       " 'ivanka',\n",
       " 'trump',\n",
       " 'donald',\n",
       " 'trump',\n",
       " 'jr',\n",
       " 'may',\n",
       " 'present',\n",
       " 'oversee',\n",
       " 'primary',\n",
       " 'assistants',\n",
       " 'trump',\n",
       " 'adult',\n",
       " 'children',\n",
       " 'internal',\n",
       " 'operations',\n",
       " 'floor',\n",
       " 'trump',\n",
       " 'tower',\n",
       " 'provide',\n",
       " 'personal',\n",
       " 'assistance',\n",
       " 'eric',\n",
       " 'f',\n",
       " 'trump',\n",
       " 'donald',\n",
       " 'j',\n",
       " 'trump',\n",
       " 'jr',\n",
       " 'ivanka',\n",
       " 'trump',\n",
       " 'including',\n",
       " 'calendar',\n",
       " 'travel',\n",
       " 'expenses',\n",
       " 'purchases',\n",
       " 'event',\n",
       " 'coordination',\n",
       " 'contact',\n",
       " 'engagements',\n",
       " 'well',\n",
       " 'home',\n",
       " 'business',\n",
       " 'responsibilities',\n",
       " 'conjunction',\n",
       " 'two',\n",
       " 'primary',\n",
       " 'assistants',\n",
       " 'handle',\n",
       " 'celebrity',\n",
       " 'talent',\n",
       " 'acquisition',\n",
       " 'bookings',\n",
       " 'work',\n",
       " 'tandem',\n",
       " 'executive',\n",
       " 'director',\n",
       " 'eric',\n",
       " 'trump',\n",
       " 'foundation',\n",
       " 'oversee',\n",
       " 'operations',\n",
       " 'volunteers',\n",
       " 'events',\n",
       " 'outreach',\n",
       " 'vendors',\n",
       " 'corporate',\n",
       " 'partnerships',\n",
       " 'acquire',\n",
       " 'celebrity',\n",
       " 'donations',\n",
       " 'experiences',\n",
       " 'eric',\n",
       " 'trump',\n",
       " 'foundation',\n",
       " 'line',\n",
       " 'charity',\n",
       " 'buzz',\n",
       " 'auction',\n",
       " 'eric',\n",
       " 'trump',\n",
       " 'foundation',\n",
       " 'annual',\n",
       " 'golf',\n",
       " 'invitational',\n",
       " 'live',\n",
       " 'auction',\n",
       " 'responsible',\n",
       " 'organizing',\n",
       " 'executing',\n",
       " 'overseeing',\n",
       " 'etf',\n",
       " 'operations',\n",
       " 'philanthropic',\n",
       " 'events',\n",
       " 'golf',\n",
       " 'tournaments',\n",
       " 'social',\n",
       " 'media',\n",
       " 'websites',\n",
       " 'identify',\n",
       " 'develop',\n",
       " 'viable',\n",
       " 'partnerships',\n",
       " 'research',\n",
       " 'projects',\n",
       " 'etf',\n",
       " 'conjunction',\n",
       " 'etf',\n",
       " 'executive',\n",
       " 'director',\n",
       " 'st',\n",
       " 'jude',\n",
       " 'children',\n",
       " 'research',\n",
       " 'hospital']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "apparently, while it is technically possible for RNNs to handle variable input length input,\n",
    "in practice this makes things tricky. \n",
    "here's the preprocessing steps i've seen other people use:\n",
    "1 - tokenise (i.e. split article into individual words)\n",
    "2 - use this to build a dictionary of individual words\n",
    "3 - rank order by word frequency\n",
    "4 - consider only the most common n words (e.g. a dictionary of 40,000)\n",
    "5 - assign each word a number based on it's position in the ranked frequency\n",
    "6 - choose a 'sentence length' hyperparameter. ours may be in the hundreds because the articles are longer than other nlp data ive seen (tweets)\n",
    "7 - use the word number ids for each article in the right order to get a vector of length==sentence_length (e.g. [34,1,2,45,3, ...], or [0,0,0,0,34,56, ...])\n",
    "This fixed sentence length makes things like batch processing play much nicer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m xx \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mxx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  \"\"\"\n",
    "  Initialize MLP Network\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, actv, input_feature_num, hidden_unit_nums, output_feature_num):\n",
    "    \"\"\"\n",
    "    Initialize MLP Network parameters\n",
    "\n",
    "    Args:\n",
    "      actv: string\n",
    "        Activation function\n",
    "      input_feature_num: int\n",
    "        Number of input features\n",
    "      hidden_unit_nums: list\n",
    "        Number of units per hidden layer, list of integers\n",
    "      output_feature_num: int\n",
    "        Number of output features\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    super(Net, self).__init__()\n",
    "    self.input_feature_num = input_feature_num # Save the input size for reshaping later\n",
    "    self.mlp = nn.Sequential() # Initialize layers of MLP\n",
    "\n",
    "    in_num = input_feature_num # Initialize the temporary input feature to each layer\n",
    "    for i in range(len(hidden_unit_nums)): # Loop over layers and create each one\n",
    "\n",
    "      out_num = hidden_unit_nums[i] # Assign the current layer hidden unit from list\n",
    "      layer = nn.Linear(in_num, out_num) # Use nn.Linear to define the layer\n",
    "      in_num = out_num # Assign next layer input using current layer output\n",
    "      self.mlp.add_module('Linear_%d'%i, layer) # Append layer to the model with a name\n",
    "\n",
    "      actv_layer = eval('nn.%s'%actv) # Assign activation function (eval allows us to instantiate object from string)\n",
    "      self.mlp.add_module('Activation_%d'%i, actv_layer) # Append activation to the model with a name\n",
    "\n",
    "    out_layer = nn.Linear(in_num, output_feature_num) # Create final layer\n",
    "    self.mlp.add_module('Output_Linear', out_layer) # Append the final layer\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    Simulate forward pass of MLP Network\n",
    "\n",
    "    Args:\n",
    "      x: torch.tensor\n",
    "        Input data\n",
    "\n",
    "    Returns:\n",
    "      logits: Instance of MLP\n",
    "        Forward pass of MLP\n",
    "    \"\"\"\n",
    "    # Reshape inputs to (batch_size, input_feature_num)\n",
    "    # Just in case the input vector is not 2D, like an image!\n",
    "    x = x.view(-1, self.input_feature_num)\n",
    "\n",
    "    logits = self.mlp(x) # Forward pass of MLP\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets define our recurrent model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNLP(nn.module):\n",
    "    def __init__(self, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
